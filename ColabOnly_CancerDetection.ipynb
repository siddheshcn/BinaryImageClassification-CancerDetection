{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "toc_visible": true,
      "mount_file_id": "1nfgWxiRpBxTz8jx6ZhiRGZqkOoHyFhO3",
      "authorship_tag": "ABX9TyORtNuJNVlbiWh58H1SMSxP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/siddheshcn/BinaryImageClassification-CancerDetection/blob/main/ColabOnly_CancerDetection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Environment Setup\n",
        "\n",
        "```\n",
        "# This is formatted as code\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "cWOUJnoVAKVS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "6P57mwlobBH9"
      },
      "outputs": [],
      "source": [
        "# IMport Libraies\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "np.random.seed(101)\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Dropout, Flatten, Activation\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "import os\n",
        "import cv2\n",
        "import json\n",
        "\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import itertools\n",
        "import shutil\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "tf.random.set_seed(101)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#setting pre-requisites\n",
        "IMAGE_SIZE = 96\n",
        "IMAGE_CHANNELS = 3\n",
        "SAMPLE_SIZE = 80000 #this will be per label"
      ],
      "metadata": {
        "id": "qhrhwB5ykpKa"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Setup Google Drive for Kaggle API, Dataset and Checkpoints"
      ],
      "metadata": {
        "id": "t42Au7OI4ivd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jwDMxrEM4yOJ",
        "outputId": "5ab39e5b-9eb2-4da2-bca4-b97d29600708"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Drag and drop kaggle json file in colab files then\n",
        "\n",
        "#Copy kaggle credentials to Google Drive\n",
        "!cp ~/.kaggle/kaggle.json /content/drive/My\\ Drive/UTD/Projects/CancerDetection/kaggle.json"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PXRuZbLu48k6",
        "outputId": "d7591866-8b10-467a-f04b-ad51caf51300"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cp: cannot stat '/root/.kaggle/kaggle.json': No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#load Kaggle credentials from Google Drive\n",
        "!mkdir -p ~/.kaggle\n",
        "!cp /content/drive/My\\ Drive/UTD/Projects/CancerDetection/kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "P0L6fa4z5y99"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Download Dataset on Google Drive and unzip"
      ],
      "metadata": {
        "id": "v8nF1skF_2sP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: copy a zip file from google drive 'histopathologic-cancer-detection' to colab files. Then unzip the files here.\n",
        "src_path = '/content/drive/My\\ Drive/UTD/Projects/CancerDetection/histopathologic-cancer-detection.zip'\n",
        "dest_path = '/content/CancerDetection/'\n",
        "os.mkdir('/content/CancerDetection/')\n",
        "\n",
        "!cp -r $src_path $dest_path\n",
        "!unzip -j /content/CancerDetection/histopathologic-cancer-detection.zip\n"
      ],
      "metadata": {
        "id": "JUDRSdDJpF6U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wDwXZnUotIfu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#download and unzip datasets to Google Drive:\n",
        "\n",
        "#set path\n",
        "dataset_path = '/content/CancerDetection/input/'\n",
        "\n",
        "#download dataset\n",
        "#kaggle competitions download -c histopathologic-cancer-detection -p $dataset_path\n",
        "\n",
        "#unzip dataset\n",
        "#!unzip /content/CancerDetection/histopathologic-cancer-detection.zip -d $dataset_path\n",
        "\n",
        "print(\"Done\")"
      ],
      "metadata": {
        "id": "Y684Q1Xj6nwI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1c0237e4-9eeb-4059-a14e-7a97a4835b67"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/CancerDetection/histopathologic-cancer-detection.zip\n",
            "replace /content/CancerDetection/input/sample_submission.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: Done\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#verify the file exists\n",
        "!ls $dataset_path"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UCQM_Hej9V5u",
        "outputId": "e4e91a7f-e481-4ae0-e34f-c22fe6d568c7"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ls: cannot access '/content/CancerDetection/input/': No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.listdir(dataset_path)"
      ],
      "metadata": {
        "id": "8VKmylPUlNCX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 144
        },
        "outputId": "ab24bf3d-bb3b-4082-86ce-fe58d2322a26"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/CancerDetection/input/'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-e63ae02ca9a9>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/CancerDetection/input/'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data Exploration"
      ],
      "metadata": {
        "id": "_hxmuUPRk6i0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Exploration"
      ],
      "metadata": {
        "id": "3BaTcexCAg6T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_path = '/content/CancerDetection/input/'"
      ],
      "metadata": {
        "id": "BUsbKtavVvgs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(os.listdir('/content/CancerDetection/input/train')))\n",
        "print(len(os.listdir('/content/CancerDetection/input/test')))"
      ],
      "metadata": {
        "id": "ZXswqQjQAkaW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Creating Dataframe of all training images"
      ],
      "metadata": {
        "id": "DglHbJS2BEnB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_data = pd.read_csv(\"/content/CancerDetection/input/train_labels.csv\")\n",
        "\n",
        "# removing this image because it caused a training error previously\n",
        "df_data[df_data['id'] != 'dd6dfed324f9fcb6f93f46f32fc800f2ec196be2']\n",
        "\n",
        "# removing this image because it's black\n",
        "df_data[df_data['id'] != '9369c7278ec8bcc6c880d99194de09fc2bd4efbe']\n",
        "\n",
        "\n",
        "print(df_data.shape)"
      ],
      "metadata": {
        "id": "Bljzf_x7BLlw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#check data distribution\n",
        "df_data['label'].value_counts()"
      ],
      "metadata": {
        "id": "eMh751j-E7GD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Check Images\n",
        "Draw Category Images\n",
        "\n",
        "    Give a column in a dataframe,\n",
        "    this function takes a sample of each class and displays that\n",
        "    sample on one row. The sample size is the same as figure_cols which\n",
        "    is the number of columns in the figure.\n",
        "    Because this function takes a random sample, each time the function is run it\n",
        "    displays different images."
      ],
      "metadata": {
        "id": "wh4fjIMfFLWt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def draw_category_images(col_name, figure_cols, df, IMAGE_PATH):\n",
        "\n",
        "  categories = (df.groupby([col_name])[col_name].nunique()).index\n",
        "  f, ax = plt.subplots(nrows=len(categories),\n",
        "                       ncols=figure_cols,\n",
        "                       figsize=(4*figure_cols, 4*len(categories))) #size can be adjusted here\n",
        "\n",
        "  #draw a number of images for each location\n",
        "  for i, cat in enumerate(categories):\n",
        "    sample = df[df[col_name]== cat].sample(figure_cols) #figure_cols is also the sample size\n",
        "    for j in range(0, figure_cols):\n",
        "      file=IMAGE_PATH + sample.iloc[j]['id'] + '.tif'\n",
        "      im=cv2.imread(file)\n",
        "      ax[i,j].imshow(im, resample=True, cmap='gray')\n",
        "      ax[i,j].set_title(cat, fontsize=16)\n",
        "  plt.tight_layout()\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "l-jzH2_8FY1V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "IMAGE_PATH = f\"/content/CancerDetection/input/train/\"\n",
        "draw_category_images('label',4,df_data, IMAGE_PATH)"
      ],
      "metadata": {
        "id": "Y5wL7MnBHEzI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create Train and Validation Datasets"
      ],
      "metadata": {
        "id": "9qOB9xiqHid7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Get same number of samples of both labels"
      ],
      "metadata": {
        "id": "HtemlkRVJSXE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_0 = df_data[df_data['label']==0].sample(SAMPLE_SIZE, random_state=101)\n",
        "df_1 = df_data[df_data['label']==1].sample(SAMPLE_SIZE, random_state=101)\n",
        "\n",
        "#concat the dataframes\n",
        "df_data = pd.concat([df_0,df_1], axis=0).reset_index(drop=True)\n",
        "#shuffle\n",
        "df_data= shuffle(df_data)\n",
        "\n",
        "df_data['label'].value_counts()"
      ],
      "metadata": {
        "id": "HGb9js77HnQa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train and Validation Split:\n",
        "- Stratify creates a balanced validation set."
      ],
      "metadata": {
        "id": "nYTAkn8EJZxt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y= df_data['label']\n",
        "\n",
        "df_train, df_val = train_test_split(df_data, test_size=0.10, random_state = 101, stratify=y)\n",
        "\n",
        "print(df_train.shape)\n",
        "print(df_val.shape)"
      ],
      "metadata": {
        "id": "Yco5wPk2JZSR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Create Directories\n",
        "Base Derectory\n",
        "* Train Directory\n",
        " *   a (no tumor tissue)\n",
        " *   b (has tumor tissue)\n",
        "\n",
        "- Validation Directory\n",
        " *   a (no tumor tissue)\n",
        " *   b (has tumor tissue)\n"
      ],
      "metadata": {
        "id": "qlJ55QvwIgOu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Create Directories\n",
        "\n",
        "#base directory\n",
        "\n",
        "base_dir = 'base_dir'\n",
        "os.mkdir(base_dir)\n",
        "\n",
        "#train directory\n",
        "train_dir = os.path.join(base_dir, 'train_dir')\n",
        "os.mkdir(train_dir)\n",
        "\n",
        "#Val dir\n",
        "val_dir = os.path.join(base_dir, 'val_dir')\n",
        "os.mkdir(val_dir)\n",
        "\n",
        "#tumor or no-tumor inside train directory\n",
        "no_tumor = os.path.join(train_dir, 'a_no_tumor')\n",
        "os.mkdir(no_tumor)\n",
        "has_tumor = os.path.join(train_dir, 'b_has_tumor')\n",
        "os.mkdir(has_tumor)\n",
        "\n",
        "#tumor or no-tumor inside val directory\n",
        "no_tumor = os.path.join(val_dir, 'a_no_tumor')\n",
        "os.mkdir(no_tumor)\n",
        "has_tumor = os.path.join(val_dir, 'b_has_tumor')\n",
        "os.mkdir(has_tumor)"
      ],
      "metadata": {
        "id": "8OZhP1YF331j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#create directories in colab\n"
      ],
      "metadata": {
        "id": "pkdqPI95iag1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#test if directories are created\n",
        "os.listdir('base_dir/train_dir')"
      ],
      "metadata": {
        "id": "kBfKhnvY6zNV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "4XG6SVYQ6yty"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#set id as index in df_data\n",
        "df_data.set_index('id', inplace=True)"
      ],
      "metadata": {
        "id": "FVstkD1O-AfE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "TESTing next code snippet"
      ],
      "metadata": {
        "id": "K7blbfWohcpm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "src = '/content/CancerDetection/input/train/'+train_list[3]\n",
        "src\n"
      ],
      "metadata": {
        "id": "P75RbDarjYSG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "OG"
      ],
      "metadata": {
        "id": "14LZSC0WhaHX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf base_dir/*"
      ],
      "metadata": {
        "id": "sgNHb0URKe4P"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Get a list of train and val images\n",
        "train_list = list(df_train['id'])\n",
        "val_list = list(df_val['id'])\n",
        "\n",
        "error_counter_train = 0\n",
        "error_counter_val = 0\n",
        "\n",
        "#transfer the train images\n",
        "for image in train_list:\n",
        "  fname = image+'.tif'\n",
        "  target = df_data.loc[image,'label']\n",
        "  if target == 0:\n",
        "    label = 'a_no_tumor'\n",
        "  if target == 1:\n",
        "    label = 'b_has_tumor'\n",
        "\n",
        "  src = '/content/CancerDetection/input/train/'+ fname\n",
        "  dst = os.path.join(train_dir, label, fname)\n",
        "  try:\n",
        "    shutil.copyfile(src, dst)\n",
        "  except:\n",
        "    error_counter_train += 1\n",
        "\n",
        "#Transfer the val images\n",
        "for image in val_list:\n",
        "  fname = image+'.tif'\n",
        "  target = df_data.loc[image,'label']\n",
        "  if target == 0:\n",
        "    label = 'a_no_tumor'\n",
        "  if target == 1:\n",
        "    label = 'b_has_tumor'\n",
        "\n",
        "\n",
        "  src = '/content/CancerDetection/input/train/'+ fname\n",
        "  dst = os.path.join(val_dir, label, fname)\n",
        "  try:\n",
        "    shutil.copyfile(src, dst)\n",
        "  except:\n",
        "    error_counter_val += 1"
      ],
      "metadata": {
        "id": "LtR8wvd5_Wfb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(error_counter_train)\n",
        "print(error_counter_val)"
      ],
      "metadata": {
        "id": "Brt8oi5m2GvS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# check how many images are present in each new folder\n",
        "print(\"Train Folder     : A(neg), B(pos)\")\n",
        "print(len(os.listdir('base_dir/train_dir/a_no_tumor')))\n",
        "print(len(os.listdir('base_dir/train_dir/b_has_tumor')))\n",
        "print(\"Validation Folder: A(neg), B(pos)\")\n",
        "print(len(os.listdir('base_dir/val_dir/a_no_tumor')))\n",
        "print(len(os.listdir('base_dir/val_dir/b_has_tumor')))"
      ],
      "metadata": {
        "id": "sY0w-3X62Puu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## SET UP GENERATORS"
      ],
      "metadata": {
        "id": "2dMecPzZ3Hzf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_path = 'base_dir/train_dir'\n",
        "val_path = 'base_dir/val_dir'\n",
        "test_path = '/content/CancerDetection/input/test'\n",
        "\n",
        "num_train_samples = len(df_train)\n",
        "num_val_samples = len(df_val)\n",
        "num_test_samples = len(os.listdir(test_path))\n",
        "\n",
        "train_batch_size = 10\n",
        "val_batch_size = 10\n",
        "\n",
        "train_steps = np.ceil(num_train_samples / train_batch_size)\n",
        "val_steps = np.ceil(num_val_samples / val_batch_size)"
      ],
      "metadata": {
        "id": "A1Jwso3G3LTP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#ImageDATAgenerator\n",
        "\n",
        "datagen = ImageDataGenerator(rescale= 1.0/255)\n",
        "\n",
        "train_gen = datagen.flow_from_directory(\n",
        "    train_path,\n",
        "    target_size=(IMAGE_SIZE, IMAGE_SIZE),\n",
        "    batch_size=train_batch_size,\n",
        "    class_mode='categorical')\n",
        "\n",
        "val_gen = datagen.flow_from_directory(\n",
        "    val_path,\n",
        "    target_size=(IMAGE_SIZE, IMAGE_SIZE),\n",
        "    batch_size=val_batch_size,\n",
        "    class_mode='categorical')\n",
        "\n",
        "test_gen = datagen.flow_from_directory(\n",
        "    val_path,\n",
        "    target_size=(IMAGE_SIZE, IMAGE_SIZE),\n",
        "    batch_size=1,\n",
        "    class_mode=None,\n",
        "    shuffle=False) #shuffle=False as it is test data that we need not shuffle"
      ],
      "metadata": {
        "id": "fxgm-u3r9wJB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Convoluted NN Models"
      ],
      "metadata": {
        "id": "1AlkRsAc-liA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "kernel_size = (3,3)\n",
        "pool_size = (2,2)\n",
        "first_filters = 32\n",
        "second_filters = 64\n",
        "third_filters = 128\n",
        "\n",
        "dropout_conv = 0.3\n",
        "dropout_dense = 0.3\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Conv2D(first_filters, kernel_size, activation = 'relu', input_shape = (96, 96, 3)))\n",
        "model.add(Conv2D(first_filters, kernel_size, activation = 'relu'))\n",
        "model.add(Conv2D(first_filters, kernel_size, activation = 'relu'))\n",
        "model.add(MaxPooling2D(pool_size = pool_size))\n",
        "model.add(Dropout(dropout_conv))\n",
        "\n",
        "model.add(Conv2D(second_filters, kernel_size, activation ='relu'))\n",
        "model.add(Conv2D(second_filters, kernel_size, activation ='relu'))\n",
        "model.add(Conv2D(second_filters, kernel_size, activation ='relu'))\n",
        "model.add(MaxPooling2D(pool_size = pool_size))\n",
        "model.add(Dropout(dropout_conv))\n",
        "\n",
        "model.add(Conv2D(third_filters, kernel_size, activation ='relu'))\n",
        "model.add(Conv2D(third_filters, kernel_size, activation ='relu'))\n",
        "model.add(Conv2D(third_filters, kernel_size, activation ='relu'))\n",
        "model.add(MaxPooling2D(pool_size = pool_size))\n",
        "model.add(Dropout(dropout_conv))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(256, activation = \"relu\"))\n",
        "model.add(Dropout(dropout_dense))\n",
        "model.add(Dense(2, activation = \"softmax\"))\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "53Lz3Nxg-qU5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(Adam(learning_rate=0.0001), loss='binary_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "36wON_zEPFqE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#get the labels associated with each index:\n",
        "print(val_gen.class_indices)"
      ],
      "metadata": {
        "id": "rcygdLuUPT2g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Generate Directory to save models\n",
        "\n",
        "model_dir = '/content/CancerDetection/Model/'\n",
        "os.mkdir(model_dir)\n",
        "\n",
        "#train directory\n",
        "#train_dir = os.path.join(base_dir, 'train_dir')\n",
        "#os.mkdir(train_dir)"
      ],
      "metadata": {
        "id": "E6Kt6nL7QgbN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "filepath = \"/content/CancerDetection/Model/model.h5\"\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
        "callbacks_list = [checkpoint]\n",
        "\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=2, min_lr=0.00001)\n",
        "\n",
        "callbacks_list = [checkpoint, reduce_lr]\n",
        "\n",
        "history = model.fit(train_gen, steps_per_epoch=train_steps,\n",
        "                              epochs=3,\n",
        "                              validation_data=val_gen,\n",
        "                              validation_steps=val_steps,\n",
        "                              callbacks=callbacks_list)"
      ],
      "metadata": {
        "id": "xCj91KkoPdZ9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}